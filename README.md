# Dear colleagues
Join us for our workshop on "generative methods: investigating the use of generative artificial intelligence for the social study of science and technology" taking place in Zurich on Thursday, 11. September 14h30 - 16h00, during the STS-CH 2025 conference!\
More info on the conference can be found on https://sts-ch.org/sts-ch-2025/

# Workshop concept
STS scholars have highlighted the inventive (Wakeford and Lury 2014), multifarious (Marres 2017), political and often messy (Law 2004; 2006) character of scientific methods and instruments. Acknowledging Latour’s (2004) consideration that critique has run out of steam, STS embraces a non-representational approach to methods which enact scientific realities (Licoppe 2010).

With this in mind, how might we situate the advent of GenAI (Generative AI) in the mix of available avenues to conduct and reflect on STS research? In the workshop, we will evaluate what role GenAI could play, or already plays, to investigate STS subjects, what epistemological challenges can come with the many shortcomings of this technology discussed in the literature (epistemic opacity, data biases, systematic unreliability) and to what extend we can accommodate ethical concerns that come with the socio-technical operationalization of this technology (privacy violations, ecological footprint, algorithmic discrimination, global injustice).

Drawing on Preda’s work on the role of the stock ticker as generator of financial markets (2006), we could evaluate if and how GenAI serves as a generative method for STS in the sense that it reconfigures scientific temporalities, agencies and assemblages. And last but not least, we also want to examine how we can ensure to hold things together in this potentially fluid and unstable course of action - at least as far as we want to. We invite participants to report, debate and experiment with directions involving GenAI to generate new research questions, objects, actors, data, tools and insights.

# Contributions

## Jana Hecktor

**Prompted Possibilities:  Integrating Generative Models into Participatory Scenario Design** 
 
Generative AI is at the forefront of the current hype around Artificial Intelligence. It’s capacity to create content – from images and videos to its most prominent output: text – not only sparked debate about humans unique selling point of being able to create ⁄meaningful/ content but lead to an ubiquitary use of these systems in heterogenous discourse fields. Research on the one hand started to analyze the influence and consequences these systems have (for areas as education, the creative industry, for vulnerable groups in general etc.). On the other hand, generative AI has also become a tool used within research processes. Many discussions sparked around if and how such a usage should be marked, made transparent, be regulated or forbidden due to commonly known risks (e.g. privacy and copyright issues). But it has also been acknowledged how productive and helpful these systems might be – if used consciously and with the right amount of knowledge and literacy. 
 
One example of that which I want to discuss is using generative AI systems such as GPT, for the creation of scenarios. Bringing with me some first experience in doing so within an interdisciplinary group of researchers, I want to talk about how this can work, what benefits research can gain but also what the difficulties and possible problems had been. Of course, one has to keep in mind also the general critiques on generative AI, beginning with its environmental impact, possible biases and discriminatory dimensions as well as consequences for vulnerable groups. But this doesn’t necessarily mean those systems shouldn’t be used in general. I would argue that the rightfully discussed negative consequences of these systems deems it necessary, that we as researchers take a close look, a critical perspective on the possible usage of this technology and decide to use it intentionally and based on a proper weighing of positive and negative dimensions. 
 
Of course, one has to keep in mind the general critiques of generative AI, beginning with its environmental impact, possible biases and discriminatory dimensions as well as consequences for vulnerable groups. But this doesn’t necessarily mean those systems shouldn’t be used. I would argue, that the rightfully discussed negative consequences of these systems deems it necessary, that we as researchers, take a close look and take a critical stance on the possible usage of this technology and should decide to use it intentionally and based on a proper weighing of positive and negative dimensions.

## Lisa Koeritz
**“AI Ethics Navigator" - Navigating the intricate landscape of ethical guidelines**
Interactions with generative AI, especially large language models such as GPT, Gemini or Claude, whether through chatbots or integrated in algorithms, have become commonplace for many in daily life in recent years. Consequently, applying generative AI methods is currently being explored in research contexts as well. 

In this context, I aim to discuss the challenges and perspectives of using generative methods to investigate the deliberation with ethical frameworks in the development and application of AI technologies for responsible innovation arising from our development and exploration of the "AI Ethics Navigator", an interactive generative AI tool.  

Traditionally, interactions with ethical guidelines occur through static PDF documents from industry or policy contexts, which include detailed descriptions and scenarios outlining contextualized approaches or strategic recommendations. Concurrently, there is a growing number of tools that facilitate more interactive and integrative approaches to ethical deliberation. 

Through the discussion and testing of our tool with potential users in the context of publicly funded integrated research projects, I analyze the challenges that arise in engaging with generative AI when addressing ethical questions for responsible AI. We will also present the tool "AI Ethics Navigator" as an example of how generative AI can reduce complexity and provide guidance in navigating the intricate landscape of ethical considerations. 

The “AI Ethics Navigator” works as a question-answering system for a database of over 200 ethical framework offering users a structured interface providing contextualized answers as well as points to references for users’ questions. By leveraging generative AI, the tool assists users in generating context-specific understanding, thereby enhancing the decision-making process in ethical contexts.  

Participants are invited to engage in a critical dialogue about the implications of our findings and the potential for generative AI tools to transform ethical deliberation in research and practice. 
